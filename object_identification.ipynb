{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from rembg import remove\n",
    "\n",
    "# denoise\n",
    "from skimage import io\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage import img_as_ubyte, img_as_float\n",
    "\n",
    "from skimage.morphology import dilation\n",
    "from skimage.morphology import rectangle\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230109_171910.jpg\n",
      "20230109_171922.jpg\n",
      "20230109_171941.jpg\n",
      "20230109_171951.jpg\n",
      "20230109_172007.jpg\n",
      "20230109_172038.jpg\n",
      "(512, 512, 3)\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./images/\"\n",
    "\n",
    "images_list = os.listdir(image_path)\n",
    "\n",
    "images = []\n",
    "gray_images = []\n",
    "for image in images_list:\n",
    "    print(image)\n",
    "    img = cv2.imread(image_path + image)\n",
    "    resized = cv2.resize(img, (512, 512), interpolation=cv2.INTER_AREA)\n",
    "    images.append(resized)\n",
    "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    gray_images.append(gray)\n",
    "\n",
    "print(images[0].shape)\n",
    "print(gray_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_seg(img):\n",
    "    # ret, thresh = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
    "    # ret, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    ret, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_TRIANGLE)\n",
    "\n",
    "    return thresh\n",
    "\n",
    "def denoise(img):\n",
    "    float_img = img_as_float(img)\n",
    "    sigma_est = np.mean(estimate_sigma(img, channel_axis=-1))\n",
    "    denoise_img = denoise_nl_means(float_img, h=1.15 * sigma_est, fast_mode=True, \n",
    "                               patch_size=5, patch_distance=3, channel_axis=-1)\n",
    "    denoise_img_as_8byte = img_as_ubyte(denoise_img)\n",
    "    # gray = cv2.cvtColor(denoise_img_as_8byte, cv2.COLOR_BGR2GRAY)\n",
    "    return denoise_img_as_8byte\n",
    "\n",
    "def multi_dil(im,num):\n",
    "    for i in range(num):\n",
    "        im = dilation(im)\n",
    "    return im"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(final_path, img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_AREA)\n",
    "    rembg_img = remove(img)\n",
    "    denoised = denoise(rembg_img)\n",
    "    gray = cv2.cvtColor(denoised, cv2.COLOR_BGR2GRAY)\n",
    "    segmented = cv_seg(gray)\n",
    "    dilated = multi_dil(segmented, 3)\n",
    "    label_im = label(segmented)\n",
    "    for num, i in enumerate(regionprops(label_im)):\n",
    "        minr, minc, maxr, maxc = i.bbox\n",
    "        roi = img[minr:maxr, minc:maxc]\n",
    "        cv2.imwrite(final_path + f\"{num}.jpg\", roi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crop base image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop(\"./base_img/\", \"./images/20230109_171941.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crop test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(\"./test_img/\", \"./images/20230109_171922.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening cropped objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening objects\n",
    "base_objects = os.listdir(\"./base_img/\")\n",
    "test_objects = os.listdir(\"./test_img/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for obj in base_objects:\n",
    "    base_imgs.append( cv2.imread(\"./base_img/\" + obj))\n",
    "\n",
    "for obj in test_objects:\n",
    "    test_imgs.append( cv2.imread(\"./test_img/\" + obj))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming objects for easier identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pen = test_imgs[0]\n",
    "test_botton = test_imgs[1]\n",
    "# test_tape = test_imgs[0]\n",
    "# test_drive = test_imgs[4]\n",
    "# test_ears = test_imgs[2]\n",
    "test_support = test_imgs[2]\n",
    "test_cable = test_imgs[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pen = base_imgs[0]\n",
    "base_botton = base_imgs[3]\n",
    "base_tape = base_imgs[5]\n",
    "base_drive = base_imgs[6]\n",
    "base_ears = base_imgs[2]\n",
    "base_support = base_imgs[4]\n",
    "base_cable = base_imgs[1]\n",
    "\n",
    "# test_pen = test_imgs[6]\n",
    "# test_botton = test_imgs[3]\n",
    "# test_tape = test_imgs[0]\n",
    "# test_drive = test_imgs[4]\n",
    "# test_ears = test_imgs[2]\n",
    "# test_support = test_imgs[5]\n",
    "# test_cable = test_imgs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "base_imgs = [base_pen,\n",
    "base_botton, \n",
    "base_tape, \n",
    "base_drive,\n",
    "base_ears,\n",
    "base_support, \n",
    "base_cable ]\n",
    "\n",
    "# test_imgs = [test_pen,\n",
    "# test_botton,\n",
    "# test_support,\n",
    "# test_cable]\n",
    "\n",
    "# test_imgs = [test_pen,\n",
    "# test_botton,\n",
    "# test_tape,\n",
    "# test_drive,\n",
    "# test_ears,\n",
    "# test_support,\n",
    "# test_cable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(img):\n",
    "    # Calculate histogram without mask\n",
    "    hist1 = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    hist2 = cv2.calcHist([img],[1],None,[256],[0,256])\n",
    "    hist3 = cv2.calcHist([img],[2],None,[256],[0,256])\n",
    "    # plt.subplot(221), plt.imshow(img)\n",
    "    # plt.subplot(222), plt.plot(hist1), plt.plot(hist2),plt.plot(hist3)\n",
    "    # plt.xlim([0,256])\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    return np.array([np.squeeze(hist1), np.squeeze(hist2), np.squeeze(hist3)])\n",
    "\n",
    "# def hist(img):\n",
    "#     hist = cv2.calcHist([img], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
    "#     # hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "#     plt.show()\n",
    "#     return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test tape = (25, 222)\n",
      "base tape = (103, 131)\n",
      "base tape = (48, 84)\n",
      "0.2740309790261617\n",
      "-0.06101190476190477\n"
     ]
    }
   ],
   "source": [
    "test_tape_shape = test_tape.shape[0:2]\n",
    "base_tape_shape = base_tape.shape[0:2]\n",
    "base_support_shape = base_support.shape[0:2]\n",
    "\n",
    "print(f\"test tape = {test_tape_shape}\")\n",
    "print(f\"base tape = {base_tape_shape}\")\n",
    "print(f\"base tape = {base_support_shape}\")\n",
    "\n",
    "h_ratio = 1 - abs((test_tape_shape[0] - base_tape_shape[0]) / base_tape_shape[0])\n",
    "w_ratio = 1 - abs((test_tape_shape[1] - base_tape_shape[1]) / base_tape_shape[1])\n",
    "\n",
    "mean = (h_ratio + w_ratio) / 2\n",
    "print(mean)\n",
    "\n",
    "h_ratio = 1 - abs((test_tape_shape[0] - base_support_shape[0]) / base_support_shape[0])\n",
    "w_ratio = 1 - abs((test_tape_shape[1] - base_support_shape[1]) / base_support_shape[1])\n",
    "\n",
    "mean = (h_ratio + w_ratio) / 2\n",
    "print(mean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compairing shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match --> drive   : Distance = 1.0\n",
      "Match --> botton  : Distance = 1.0\n",
      "Match --> tape    : Distance = 1.0\n",
      "Match --> cable   : Distance = 1.0\n"
     ]
    }
   ],
   "source": [
    "objs = [\"pen\", \"botton\", \"tape\", \"drive\", \"ears\", \"support\", \"cable\"]\n",
    "\n",
    "for i in range(len(test_imgs)):\n",
    "    test_shape = test_imgs[i].shape[:2]\n",
    "    aux = []\n",
    "    for j in range(len(base_imgs)):\n",
    "        base_shape = base_imgs[j].shape[:2]\n",
    "        height_ratio = 1 - abs((test_shape[0] - base_shape[0]) / base_shape[0])\n",
    "        width_ratio  = 1 - abs((test_shape[1] - base_shape[1]) / base_shape[1])\n",
    "        mean = (height_ratio + width_ratio) / 2\n",
    "        aux.append(mean)\n",
    "    maximum = max(aux)\n",
    "    index = aux.index(maximum)\n",
    "    match = objs[index]\n",
    "    print(f\"Match --> {match:8}: Distance = {maximum}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom chi-squared distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_distance(histA, histB, eps = 1e-10):\n",
    "\t# compute the chi-squared distance\n",
    "\td = 0.5 * np.sum([((a - b) ** 2) / (a + b + eps)\n",
    "\t\tfor (a, b) in zip(histA, histB)])\n",
    "\t# return the chi-squared distance\n",
    "\treturn d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pen      --> pen     : Distance = 3222.399169921875\n",
      "botton   --> botton  : Distance = 0.0\n",
      "tape     --> tape    : Distance = 0.0\n",
      "drive    --> pen     : Distance = 0.0\n",
      "ears     --> pen     : Distance = 2319.23388671875\n",
      "support  --> tape    : Distance = 5248.10791015625\n",
      "cable    --> drive   : Distance = 0.0\n"
     ]
    }
   ],
   "source": [
    "objs = [\"pen\", \"botton\", \"tape\", \"drive\", \"ears\", \"support\", \"cable\"]\n",
    "\n",
    "for i in range(len(base_imgs)):\n",
    "    aux = []\n",
    "    base_hist = hist(base_imgs[i])\n",
    "    for j in range(len(test_imgs)):\n",
    "        resized_test_img = cv2.resize(test_imgs[j], (base_imgs[i].shape[1], base_imgs[i].shape[0]), interpolation=cv2.INTER_AREA)\n",
    "        test_hist = hist(resized_test_img)\n",
    "        res = chi2_distance(base_hist, test_hist)\n",
    "        aux.append(res)\n",
    "    minimum = min(aux)\n",
    "    index = aux.index(minimum)\n",
    "    match = objs[index]\n",
    "    print(f\"{objs[i]:8} --> {match:8}: Distance = {minimum}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the scipy methods to compaute distances\n",
    "SCIPY_METHODS = (\n",
    "\t(\"Euclidean\", dist.euclidean),\n",
    "\t(\"Manhattan\", dist.cityblock),\n",
    "\t(\"Chebysev\", dist.chebyshev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pen      --> botton  : Distance = 619.4497680664062\n",
      "botton   --> botton  : Distance = 0.0\n",
      "tape     --> tape    : Distance = 0.0\n",
      "drive    --> pen     : Distance = 0.0\n",
      "ears     --> botton  : Distance = 441.73748779296875\n",
      "support  --> tape    : Distance = 1429.7965087890625\n",
      "cable    --> drive   : Distance = 0.0\n"
     ]
    }
   ],
   "source": [
    "objs = [\"pen\", \"botton\", \"tape\", \"drive\", \"ears\", \"support\", \"cable\"]\n",
    "\n",
    "for i in range(len(base_imgs)):\n",
    "    aux = []\n",
    "    base_hist = hist(base_imgs[i])\n",
    "    for j in range(len(test_imgs)):\n",
    "        resized_test_img = cv2.resize(test_imgs[j], (base_imgs[i].shape[1], base_imgs[i].shape[0]), interpolation=cv2.INTER_AREA)\n",
    "        test_hist = hist(resized_test_img)\n",
    "        res = dist.euclidean(base_hist.flatten(), test_hist.flatten())\n",
    "        aux.append(res)\n",
    "    minimum = min(aux)\n",
    "    index = aux.index(minimum)\n",
    "    match = objs[index]\n",
    "    print(f\"{objs[i]:8} --> {match:8}: Distance = {minimum}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV compareHist method\n",
    "\n",
    "##### cv2.compareHist(H1, H2, method)  \n",
    "**Methods**\n",
    "- cv2.HISTCMP_CORREL: Computes the correlation between the two histograms.  \n",
    "- cv2.HISTCMP_CHISQR: Applies the Chi-Squared distance to the histograms.  \n",
    "- cv2.HISTCMP_INTERSECT: Calculates the intersection between two histograms.  \n",
    "- cv2.HISTCMP_BHATTACHARYYA: Bhattacharyya distance, used to measure the “overlap” between the two histograms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD #1: UTILIZING OPENCV\n",
    "# initialize OpenCV methods for histogram comparison\n",
    "OPENCV_METHODS = (\n",
    "\t(\"Correlation\", cv2.HISTCMP_CORREL),\n",
    "\t(\"Chi-Squared\", cv2.HISTCMP_CHISQR),\n",
    "\t(\"Intersection\", cv2.HISTCMP_INTERSECT),\n",
    "\t(\"Hellinger\", cv2.HISTCMP_BHATTACHARYYA))\n",
    "    \n",
    "# loop over the comparison methods\n",
    "for (methodName, method) in OPENCV_METHODS:\n",
    "\t# initialize the results dictionary and the sort\n",
    "\t# direction\n",
    "\tresults = {}\n",
    "\treverse = False\n",
    "\t# if we are using the correlation or intersection\n",
    "\t# method, then sort the results in reverse order\n",
    "\tif methodName in (\"Correlation\", \"Intersection\"):\n",
    "\t\treverse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m base_hist \u001b[39m=\u001b[39m hist(base_imgs[i])\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(base_imgs)):\n\u001b[1;32m----> 7\u001b[0m     resized_test_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(test_imgs[j], (base_imgs[i]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], base_imgs[i]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_AREA)\n\u001b[0;32m      8\u001b[0m     test_hist \u001b[39m=\u001b[39m hist(resized_test_img)\n\u001b[0;32m      9\u001b[0m     res \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcompareHist(base_hist, test_hist, cv2\u001b[39m.\u001b[39mHISTCMP_BHATTACHARYYA) \n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "objs = [\"pen\", \"botton\", \"tape\", \"drive\", \"ears\", \"support\", \"cable\"]\n",
    "\n",
    "for i in range(len(test_imgs)):\n",
    "    aux = []\n",
    "    base_hist = hist(base_imgs[i])\n",
    "    for j in range(len(base_imgs)):\n",
    "        resized_test_img = cv2.resize(test_imgs[j], (base_imgs[i].shape[1], base_imgs[i].shape[0]), interpolation=cv2.INTER_AREA)\n",
    "        test_hist = hist(resized_test_img)\n",
    "        res = cv2.compareHist(base_hist, test_hist, cv2.HISTCMP_BHATTACHARYYA) \n",
    "        aux.append(res)\n",
    "    minimum = min(aux)\n",
    "    index = aux.index(minimum)\n",
    "    match = objs[index]\n",
    "    print(f\"{objs[i]:8} --> {match:8}: Distance = {minimum}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(A, B):\n",
    "    return (((A - B) ** 2) ** (1/2)).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE in raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pen      --> cable   : rmse = 8.46090933347273\n",
      "botton   --> botton  : rmse = 7.0254464599356385\n",
      "tape     --> tape    : rmse = 7.505118462601605\n",
      "drive    --> ears    : rmse = 8.213454592328622\n",
      "ears     --> ears    : rmse = 6.476090556032647\n",
      "support  --> support : rmse = 5.997252541939605\n",
      "cable    --> cable   : rmse = 6.176245321734958\n"
     ]
    }
   ],
   "source": [
    "objs = [\"pen\", \"botton\", \"tape\", \"drive\", \"ears\", \"support\", \"cable\"]\n",
    "\n",
    "for i in range(len(base_imgs)):\n",
    "    aux = []\n",
    "    for j in range(len(test_imgs)):\n",
    "        resized_test_img = cv2.resize(test_imgs[j], (base_imgs[i].shape[1], base_imgs[i].shape[0]), interpolation=cv2.INTER_AREA)\n",
    "        res = rmse(base_imgs[i], resized_test_img)\n",
    "        # print(f\"{objs[i]} --> {objs[j]}: msre = {res}\")\n",
    "        aux.append(res)\n",
    "    minimum = min(aux)\n",
    "    index = aux.index(minimum)\n",
    "    match = objs[index]\n",
    "    print(f\"{objs[i]:8} --> {match:8}: rmse = {minimum}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE between histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pen      --> ears    : rmse = 13.7109375\n",
      "botton   --> botton  : rmse = 7.8046875\n",
      "tape     --> tape    : rmse = 26.15104103088379\n",
      "drive    --> ears    : rmse = 8.8359375\n",
      "ears     --> ears    : rmse = 4.841145992279053\n",
      "support  --> support : rmse = 13.84375\n",
      "cable    --> cable   : rmse = 44.27604293823242\n"
     ]
    }
   ],
   "source": [
    "objs = [\"pen\", \"botton\", \"tape\", \"drive\", \"ears\", \"support\", \"cable\"]\n",
    "\n",
    "for i in range(len(base_imgs)):\n",
    "    aux = []\n",
    "    base_hist = hist(base_imgs[i])\n",
    "    for j in range(len(test_imgs)):\n",
    "        resized_test_img = cv2.resize(test_imgs[j], (base_imgs[i].shape[1], base_imgs[i].shape[0]), interpolation=cv2.INTER_AREA)\n",
    "        test_hist = hist(resized_test_img)\n",
    "        res = rmse(base_hist, test_hist)\n",
    "        aux.append(res)\n",
    "    minimum = min(aux)\n",
    "    index = aux.index(minimum)\n",
    "    match = objs[index]\n",
    "    print(f\"{objs[i]:8} --> {match:8}: rmse = {minimum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase_dir(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 18 (3559880687.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[40], line 20\u001b[1;36m\u001b[0m\n\u001b[1;33m    base = hist(base)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 18\n"
     ]
    }
   ],
   "source": [
    "def match(base, test):\n",
    "    base_histograms = []\n",
    "    \n",
    "    test_imgs = []\n",
    "\n",
    "\n",
    "    for image in images_list:\n",
    "        erase_dir(test_imgs)\n",
    "        crop(\"./test_img/\", \"./images/\" + image)\n",
    "        test_objects = os.listdir(\"./test_img/\")\n",
    "        for obj in test_objects:\n",
    "            test_imgs.append( cv2.imread(\"./test_img/\" + obj))\n",
    "\n",
    "        \n",
    "        test_histograms = []\n",
    "\n",
    "        \n",
    "        for i in range(len(base_histograms)):\n",
    "                \n",
    "        base = hist(base)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_histograms = []\n",
    "for img in base_imgs:\n",
    "    base_histograms.append(hist(img))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching shape and histogram distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match --> ears    : Distance = 0.343463611455811\n",
      "Match --> botton  : Distance = 0.4523030171106842\n",
      "Match --> tape    : Distance = 0.40078003350806696\n",
      "Match --> cable   : Distance = 0.4837320994273535\n",
      "missing objects: ['pen', 'drive', 'support']\n"
     ]
    }
   ],
   "source": [
    "objs = [\"pen\", \"botton\", \"tape\", \"drive\", \"ears\", \"support\", \"cable\"]\n",
    "actual_img = []\n",
    "\n",
    "for i in range(len(test_imgs)):\n",
    "    aux = []\n",
    "    test_shape = test_imgs[i].shape[:2]\n",
    "    test_hist = hist(test_imgs[i])\n",
    "    for j in range(len(base_imgs)):\n",
    "        base_shape = base_imgs[j].shape[:2]\n",
    "        height_ratio = 1 - abs((test_shape[0] - base_shape[0]) / base_shape[0])\n",
    "        width_ratio  = 1 - abs((test_shape[1] - base_shape[1]) / base_shape[1])\n",
    "        mean = (height_ratio + width_ratio) / 2\n",
    "        if mean >= 0.75:\n",
    "            resized_test_img = cv2.resize(test_imgs[i], (base_imgs[j].shape[1], base_imgs[j].shape[0]), interpolation=cv2.INTER_AREA)\n",
    "            test_hist = hist(resized_test_img)\n",
    "            res = cv2.compareHist(base_hist, test_hist, cv2.HISTCMP_BHATTACHARYYA) \n",
    "            aux.append(res)\n",
    "        else:\n",
    "            aux.append(1)\n",
    "    minimum = min(aux)\n",
    "    index = aux.index(minimum)\n",
    "    match = objs[index]\n",
    "    if minimum != 1:\n",
    "        print(f\"Match --> {match:8}: Distance = {minimum}\")\n",
    "        actual_img.append(match)\n",
    "\n",
    "# missing = [element for element in objs if element not in actual_img]\n",
    "print(f\"missing objects: {list(element for element in objs if element not in actual_img)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visinspec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d6538569678792e77e64bdb470768aae532ff92debe953d9f27dc5810102e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
